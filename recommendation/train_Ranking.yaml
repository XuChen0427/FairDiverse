{
   model: gru4rec,
   data_type: 'sequential', #[point, pair, sequential]

#   model: gru4rec,
#   data_type: 'sequential', #[point, pair, sequential]

   ####fair-rank model settings
   fair-rank: True, ##if you want to run a fair-rank module on the base models, you should set the value as True
   rank_model: 'APR',


   # LLM recommendation setting
   use_llm: True,
   llm_type: local,     # choose from ['api', 'local']
   llm_name: Llama3-8B,     # choose from ['Llama3-8B', 'Qwen2-7B']
   grounding_model: Llama3-8B,   #  choose from ['Llama3-8B-Instruct', 'bert', 'gpt2']
   saved_embs_filename: "./llm/stored_embs/embs.pt",  # choose from [None, 'path']
   fair_prompt: "You are a item-fair recommender. Please try to ensure that each category of items receives fair recommendations.",


   log_name: "steam-APR-base_mf",
   mmf_eval_ratio: 0.5,
   decimals: 4,

   device: cuda,
   epoch: 20,
   batch_size: 32,
   learning_rate: 0.001,

   eval_step: 10,
   eval_type: 'ranking',
   watch_metric: 'mmf@20',

   topk: [ 5,10,20,50 ], # if you choose the ranking settings, you can choose your top-k list
   store_scores: True,
}